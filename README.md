# Dubbler Pro - Pipeline de Dublagem AutomÃ¡tica (v2.0)

Sistema automatizado para dublagem de vÃ­deos utilizando InteligÃªncia Artificial. O projeto realiza transcriÃ§Ã£o, traduÃ§Ã£o, sÃ­ntese de voz (TTS) e sincronizaÃ§Ã£o labial (em desenvolvimento/sincronia temporal), tudo otimizado para GPUs NVIDIA.

---

## ğŸš€ Features

- **Arquitetura Modular**: CÃ³digo organizado em serviÃ§os independentes (`src/services/`) para fÃ¡cil manutenÃ§Ã£o.
- **MÃºltiplos Motores TTS**:
  - **MMS-TTS (Facebook)**: RÃ¡pido, leve e totalmente offline.
  - **Coqui XTTS v2**: Alta qualidade com clonagem de voz (Voice Cloning) a partir do vÃ­deo original.
- **Encoding Inteligente**:
  - **Modo RÃ¡pido**: AceleraÃ§Ã£o via GPU (`h264_nvenc`).
  - **Modo Qualidade**: CompressÃ£o superior via CPU (`libx264`) com correÃ§Ã£o automÃ¡tica de Ã¡udio.
- **ResiliÃªncia**: Tratamento robusto de erros (WinError 6, falhas de I/O) e limpeza automÃ¡tica de recursos.
- **Testes Automatizados**: SuÃ­te completa (`pytest`) para validar o pipeline.

## ğŸ› ï¸ Arquitetura do Projeto

O sistema foi refatorado para seguir boas prÃ¡ticas de Engenharia de Software:

```
video-dub/
â”œâ”€â”€ main_refactored.py       # Ponto de Entrada CLI (Entrypoint)
â”œâ”€â”€ download_models.py       # Script para download de modelos offline
â”œâ”€â”€ run_app.ps1             # Inicializador da interface web
â”œâ”€â”€ pyproject.toml          # ConfiguraÃ§Ã£o do projeto e dependÃªncias (uv)
â”œâ”€â”€ tests/                  # Testes Automatizados (pytest)
â””â”€â”€ src/                    # CÃ³digo Fonte Modular
    â”œâ”€â”€ config.py           # ConfiguraÃ§Ãµes Globais (Caminhos, GPU, Modo Offline)
    â”œâ”€â”€ pipeline.py         # Orquestrador Principal
    â”œâ”€â”€ utils.py            # FunÃ§Ãµes Auxiliares (FFmpeg helper, logs)
    â”œâ”€â”€ services/           # ServiÃ§os Especializados de IA
    â”‚   â”œâ”€â”€ audio.py        # ExtraÃ§Ã£o de Ãudio e TranscriÃ§Ã£o (Whisper)
    â”‚   â”œâ”€â”€ translation.py  # TraduÃ§Ã£o Neural (NLLB)
    â”‚   â”œâ”€â”€ tts.py          # SÃ­ntese de Voz (MMS/Coqui)
    â”‚   â””â”€â”€ video.py        # SincronizaÃ§Ã£o e RenderizaÃ§Ã£o (MoviePy)
    â”œâ”€â”€ backend/            # API FastAPI para interface web
    â”‚   â””â”€â”€ app.py          # Endpoints e WebSocket para progresso
    â””â”€â”€ frontend/           # Interface Vue.js
        â”œâ”€â”€ src/            # Componentes Vue
        â””â”€â”€ package.json    # DependÃªncias do frontend
```

## ğŸ“‹ PrÃ©-requisitos

- **Python**: 3.11 (gerenciado pelo uv)
- **FFmpeg**: Instalado e acessÃ­vel no PATH (o script tenta detectar automaticamente)
- **GPU NVIDIA** (Opcional, mas recomendado): Para transcriÃ§Ã£o Whisper e codec NVENC
- **CUDA Toolkit**: 12.4 (configurado automaticamente com PyTorch)
- **Node.js**: Para executar a interface web (opcional)

## ğŸ“¦ InstalaÃ§Ã£o

### 1. Instalar o uv (Gerenciador de Pacotes Python)

O projeto usa o [uv](https://github.com/astral-sh/uv), um gerenciador de pacotes Python extremamente rÃ¡pido escrito em Rust.

**Windows (PowerShell):**
```powershell
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
```

**Linux/macOS:**
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

**Verificar instalaÃ§Ã£o:**
```bash
uv --version
```

### 2. Clonar e Configurar o Projeto

1. Clone o repositÃ³rio e entre na pasta.
2. Instale as dependÃªncias com `uv`:
   ```bash
   uv sync
   ```
   _Nota: O projeto usa Python 3.11 e PyTorch com CUDA 12.4 configurados automaticamente._

**O que o `uv sync` faz?**
- Cria automaticamente um ambiente virtual em `.venv/`
- Instala o Python 3.11 se necessÃ¡rio
- Instala todas as dependÃªncias do `pyproject.toml`
- Configura o PyTorch com suporte a CUDA 12.4

### ğŸ“¥ Download de Modelos para ExecuÃ§Ã£o Offline (Recomendado)

Para usar o projeto sem conexÃ£o Ã  internet, baixe os modelos uma vez:

**Windows:**
```powershell
uv run python download_models.py
```

**Linux/macOS:**
```bash
uv run python download_models.py
```

Isso baixarÃ¡ ~3.4 GB de modelos de IA. Depois, o projeto funcionarÃ¡ completamente offline!

ğŸ“– **Mais detalhes:** Veja [OFFLINE.md](OFFLINE.md)

## â–¶ï¸ Como Usar

### 1. PreparaÃ§Ã£o

**Windows:**
```powershell
uv run python main_refactored.py
```

**Linux/macOS:**
```basheo que deseja dublar na pasta `input/` e renomeie para `video_entrada.mp4` (ou ajuste no menu).

### 2. ExecuÃ§Ã£o

Execute o arquivo principal:

```powershell
uv run python main_refactored.py
```

Siga o menu interativo:

1. Escolha o motor de voz (MMS ou Coqui).
2. Escolha o modo de encoding (RÃ¡pido/GPU ou Qualidade/CPU).

**Windows (PowerShell):**
```powershell
.\run_app.ps1
```

**Linux/macOS (Bash):**
```bash
chmod +x run_app.sh  # Primeira vez apenas
./run_app.sh
```

Isso iniciarÃ¡ o backend (FastAPI) e frontend (Vue.js) em segundo plano.

2. Acesse no navegador:
   `http://localhost:5173`

3. Na interface:
   - FaÃ§a upload do vÃ­deo.
   - Escolha o Motor (MMS/Coqui).
   - Acompanhe o progresso no terminal embutido.
   - Baixe o vÃ­deo final diretamente da pÃ¡gina.

**Logs:** Os logs sÃ£o salvos em `logs/backend.log` e `logs/frontend.log`

3. Na interface:
   - FaÃ§a upload do vÃ­deo.
   - Escolha o Motor (MMS/Coqui).
   - Acompanhe o progresso no terminal embutido.
   - Baixe o vÃ­deo final diretamente da pÃ¡gina.

## ğŸ§ª Testes

Para verificar a integridade da instalaÃ§Ã£o e do pipeline, execute a suÃ­te de testes:

```powershell
python -m pytest tests/ -v
```

Os testes validam:

- DetecÃ§Ã£o de ambiente (CUDA, FFmpeg).
- Pipeline MMS (End-to-end com vÃ­deo sintÃ©tico).
- Pipeline Coqui (Carregamento e execuÃ§Ã£o bÃ¡sica).

## âš ï¸ SoluÃ§Ã£o de Problemas Comuns

- **WinError 6 (Invalid Handle)**: Geralmente causado por antivÃ­rus ou delay de sistema de arquivos. O script possui retry automÃ¡tico.
- **VÃ­deo sem Ãudio**: Use o modo "Qualidade" ou garanta que o FFmpeg esteja atualizado. O script forÃ§a muxing de Ã¡udio `aac` para compatibilidade.
- **Accessing time... Error**: Erro de ponto flutuante do MoviePy corrigido nesta versÃ£o via padding de Ã¡udio.

## ğŸ“š CitaÃ§Ã£o

Se vocÃª usar este projeto em sua pesquisa ou trabalho acadÃªmico, por favor cite:

```bibtex
@software{amaral2026videodub,
  author       = {Maxwell Anderson Ielpo do Amaral},
  title        = {Video Dubbing System: AI-Powered Automatic Video Dubbing with Voice Cloning},
  year         = {2026},
  publisher    = {GitHub},
  version      = {0.1.0},
  url          = {https://github.com/maxwellamaral/32-31-video-dub},
  note         = {Sistema de dublagem automÃ¡tica de vÃ­deos com IA utilizando Whisper, NLLB-200 e TTS}
}
```

Ou consulte o arquivo [CITATION.bib](CITATION.bib).

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

---

_Desenvolvido com foco em automaÃ§Ã£o e qualidade via Python._
