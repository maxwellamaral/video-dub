# Documenta√ß√£o: An√°lise de Emo√ß√µes no Pipeline de Dublagem

## Vis√£o Geral

O sistema de dublagem de v√≠deos foi aprimorado com **an√°lise de emo√ß√µes** utilizando o modelo **SenseVoiceSmall** da FunAudioLLM. Esta funcionalidade detecta automaticamente as emo√ß√µes presentes no √°udio original e as utiliza para gerar uma dublagem mais expressiva e natural com o **Qwen3-TTS**.

## Arquitetura do Sistema

### Pipeline Completo com Emo√ß√µes

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     V√çDEO DE ENTRADA                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. EXTRA√á√ÉO DE √ÅUDIO (FFmpeg)                                  ‚îÇ
‚îÇ     ‚îî‚îÄ> audio_extraido.wav                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  2. TRANSCRI√á√ÉO + AN√ÅLISE DE EMO√á√ïES                           ‚îÇ
‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ     ‚îÇ 2a. Whisper: Transcri√ß√£o com Timestamps             ‚îÇ   ‚îÇ
‚îÇ     ‚îÇ     ‚îî‚îÄ> Texto + Start/End por segmento              ‚îÇ   ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ     ‚îÇ 2b. SenseVoice: Detec√ß√£o de Emo√ß√µes                 ‚îÇ   ‚îÇ
‚îÇ     ‚îÇ     ‚îî‚îÄ> Por segmento: angry, happy, sad, neutral... ‚îÇ   ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  Resultado: Segmentos com texto + timestamps + emo√ß√£o           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  3. TRADU√á√ÉO (NLLB)                                             ‚îÇ
‚îÇ     ‚îî‚îÄ> Traduz texto preservando emo√ß√µes detectadas            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  4. S√çNTESE TTS COM EMO√á√ïES (Qwen3-TTS)                        ‚îÇ
‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ     ‚îÇ Para cada segmento:                                  ‚îÇ   ‚îÇ
‚îÇ     ‚îÇ   - Texto traduzido                                  ‚îÇ   ‚îÇ
‚îÇ     ‚îÇ   - Instru√ß√£o emocional baseada na emo√ß√£o detectada ‚îÇ   ‚îÇ
‚îÇ     ‚îÇ     Exemplo: "Fale com tom alegre e entusiasmado,   ‚îÇ   ‚îÇ
‚îÇ     ‚îÇ              voz animada, transmitindo felicidade"   ‚îÇ   ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  Resultado: √Åudio dublado com expressividade emocional          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  5. MONTAGEM FINAL (MoviePy)                                   ‚îÇ
‚îÇ     ‚îî‚îÄ> V√≠deo dublado + Legendas com tags de emo√ß√£o           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Componentes do Sistema

### 1. SenseVoiceSmall (Detec√ß√£o de Emo√ß√µes)

**Arquivo:** [`src/services/emotion.py`](../src/services/emotion.py)

**Classe Principal:** `EmotionAnalyzer`

#### Funcionalidades:
- Detecta emo√ß√µes em segmentos de √°udio
- Suporta 7 emo√ß√µes: neutral, happy, sad, angry, fearful, disgusted, surprised
- Retorna tags de emo√ß√£o e instru√ß√µes detalhadas para TTS

#### Uso:
```python
from src.services.emotion import EmotionAnalyzer

analyzer = EmotionAnalyzer(modelo="FunAudioLLM/SenseVoiceSmall")
segmentos_com_emocao = analyzer.analisar_audio(
    caminho_audio="audio.wav",
    segmentos=segmentos_transcritos
)
```

#### Formato de Sa√≠da:
Cada segmento √© enriquecido com:
```python
{
    "start": 0.5,
    "end": 3.2,
    "text": "Hello, how are you?",
    "emotion": "happy",                    # C√≥digo da emo√ß√£o
    "emotion_pt": "feliz",                 # Emo√ß√£o em portugu√™s
    "emotion_instruction": "Fale com tom alegre..."  # Instru√ß√£o para TTS
}
```

### 2. Integra√ß√£o com Whisper

**Arquivo:** [`src/services/audio.py`](../src/services/audio.py)

**Fun√ß√£o Principal:** `transcrever_com_emocao()`

Combina Whisper (transcri√ß√£o) + SenseVoice (emo√ß√µes) em uma √∫nica chamada:

```python
from src.services.audio import transcrever_com_emocao

segmentos = transcrever_com_emocao(
    caminho_audio="audio.wav",
    modelo_whisper="openai/whisper-base",
    modelo_sensevoice="FunAudioLLM/SenseVoiceSmall"
)
# Retorna segmentos com texto + timestamps + emo√ß√µes
```

### 3. Mapeamento de Emo√ß√µes para Qwen3-TTS

**Arquivo:** [`src/services/emotion.py`](../src/services/emotion.py)

As emo√ß√µes detectadas s√£o convertidas em **instru√ß√µes em linguagem natural** que o Qwen3-TTS compreende:

```python
EMOTION_INSTRUCTIONS = {
    "angry": "Fale com tom zangado, voz elevada e ritmo acelerado, demonstrando irrita√ß√£o",
    "happy": "Fale com tom alegre e entusiasmado, voz animada, transmitindo felicidade",
    "sad": "Fale com tom triste e melanc√≥lico, voz baixa e lenta, demonstrando tristeza",
    "neutral": "Fale com tom neutro e equilibrado, voz clara e natural",
    # ... outras emo√ß√µes
}
```

### 4. S√≠ntese TTS com Emo√ß√µes

**Arquivo:** [`src/services/tts.py`](../src/services/tts.py)

**Classe:** `TTSEngine`

O motor TTS foi modificado para aceitar instru√ß√µes emocionais por segmento:

```python
tts = TTSEngine(motor="qwen3", qwen3_mode="custom", qwen3_speaker="vivian")

# Entrada com emo√ß√µes
textos = [
    {
        "text": "Ol√°, como voc√™ est√°?",
        "emotion_instruction": "Fale com tom alegre e entusiasmado..."
    },
    {
        "text": "Estou muito cansado.",
        "emotion_instruction": "Fale com tom triste e melanc√≥lico..."
    }
]

audios = tts.sintetizar_batch(textos)
```

#### Modos do Qwen3-TTS:

1. **CustomVoice** (padr√£o): Usa speakers pr√©-definidos + instru√ß√£o emocional
2. **VoiceDesign**: Cria voz baseada em descri√ß√£o livre + emo√ß√£o
3. **Clone**: Clona voz de refer√™ncia + aplica emo√ß√£o

### 5. Legendas com Tags de Emo√ß√£o

**Arquivo:** [`src/utils.py`](../src/utils.py)

**Fun√ß√£o:** `segmentos_para_srt_com_emocao()`

Gera legendas SRT com tags de emo√ß√£o:

```srt
1
00:00:01,000 --> 00:00:05,500
[FELIZ] Ol√°, como voc√™ est√°?

2
00:00:06,000 --> 00:00:10,200
[TRISTE] Estou muito cansado hoje...

3
00:00:11,000 --> 00:00:15,800
Este √© um di√°logo neutro sem tag.
```

**Nota:** Segmentos com emo√ß√£o "neutral" n√£o recebem tag para evitar polui√ß√£o visual.

## Configura√ß√£o

**Arquivo:** [`src/config.py`](../src/config.py)

### Vari√°veis de Configura√ß√£o:

```python
# Habilitar/Desabilitar an√°lise de emo√ß√µes
ENABLE_EMOTION_ANALYSIS = True  # False desativa detec√ß√£o de emo√ß√µes

# Incluir tags nas legendas
INCLUDE_EMOTION_TAGS_IN_SUBTITLES = True  # [FELIZ], [TRISTE], etc.

# Modelo SenseVoice
SENSEVOICE_MODEL = "FunAudioLLM/SenseVoiceSmall"

# Emo√ß√µes suportadas
SUPPORTED_EMOTIONS = [
    "neutral", "happy", "sad", "angry",
    "fearful", "disgusted", "surprised"
]
```

## Fluxo de Dados Completo

### Entrada:
```
V√≠deo em ingl√™s com √°udio emocional (pessoa falando com raiva, alegria, etc.)
```

### Processamento:

1. **Extra√ß√£o de √Åudio:**
   ```
   video.mp4 ‚Üí audio_extraido.wav
   ```

2. **Transcri√ß√£o com Whisper:**
   ```
   "I can't believe this happened!"
   [start: 0.5s, end: 2.3s]
   ```

3. **Detec√ß√£o de Emo√ß√£o com SenseVoice:**
   ```
   Emo√ß√£o detectada: "angry" (zangado)
   Instru√ß√£o: "Fale com tom zangado, voz elevada..."
   ```

4. **Tradu√ß√£o:**
   ```
   "N√£o posso acreditar que isso aconteceu!"
   [mant√©m emo√ß√£o: "angry"]
   ```

5. **S√≠ntese TTS com Qwen3:**
   ```
   Input: texto="N√£o posso acreditar que isso aconteceu!"
          speaker="vivian"
          instruct="Fale com tom zangado, voz elevada..."
   
   Output: √°udio_pt_zangado.wav
   ```

6. **Legendas Finais:**
   ```srt
   1
   00:00:00,500 --> 00:00:02,300
   [ZANGADO] N√£o posso acreditar que isso aconteceu!
   ```

### Sa√≠da:
```
V√≠deo dublado em portugu√™s com:
- √Åudio sintetizado com expressividade emocional apropriada
- Legendas com tags de emo√ß√£o
```

## Estat√≠sticas de Emo√ß√µes

O pipeline tamb√©m gera estat√≠sticas sobre as emo√ß√µes detectadas:

```python
from src.utils import extrair_estatisticas_emocoes

stats = extrair_estatisticas_emocoes(segmentos)
# {
#     "total": 50,
#     "emocoes": {"happy": 20, "sad": 10, "neutral": 15, "angry": 5},
#     "predominante": "happy",
#     "distribuicao_percentual": {
#         "happy": 40.0,
#         "sad": 20.0,
#         "neutral": 30.0,
#         "angry": 10.0
#     }
# }
```

Exemplo de sa√≠da no log:
```
üìä Estat√≠sticas de Emo√ß√µes:
   Total de segmentos: 50
   Emo√ß√£o predominante: happy
   - happy: 20 (40.0%)
   - sad: 10 (20.0%)
   - neutral: 15 (30.0%)
   - angry: 5 (10.0%)
```

## Exemplos de Uso

### Exemplo 1: Pipeline Completo com Emo√ß√µes

```python
from src.pipeline import executar_pipeline

sucesso = executar_pipeline(
    caminho_video="input/video.mp4",
    idioma_origem="eng_Latn",
    idioma_destino="por_Latn",
    idioma_voz="por",
    motor_tts="qwen3",
    modo_encoding="qualidade",
    qwen3_mode="custom",
    qwen3_speaker="vivian"
)
```

### Exemplo 2: Apenas An√°lise de Emo√ß√µes

```python
from src.services.emotion import EmotionAnalyzer

analyzer = EmotionAnalyzer()
resultado = analyzer.analisar_audio("audio.wav")

print(f"Emo√ß√£o: {resultado['emotion']}")
print(f"Instru√ß√£o: {resultado['instruction']}")
```

### Exemplo 3: Desabilitar An√°lise de Emo√ß√µes

Em `src/config.py`:
```python
ENABLE_EMOTION_ANALYSIS = False  # Volta ao pipeline original sem emo√ß√µes
```

## Requisitos de Sistema

### Modelos Necess√°rios:

1. **Whisper** (transcri√ß√£o)
   - `openai/whisper-base` (padr√£o)
   - Outros: whisper-small, whisper-medium, whisper-large

2. **SenseVoiceSmall** (emo√ß√µes)
   - `FunAudioLLM/SenseVoiceSmall`
   - ~2GB de espa√ßo em disco

3. **Qwen3-TTS** (s√≠ntese)
   - `Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice` (padr√£o)
   - ~3.4GB de espa√ßo em disco

### Instala√ß√£o:

```bash
# Instalar depend√™ncias
uv sync

# Download dos modelos (modo offline)
python scripts/download_models.py
```

### Recursos de GPU:

- **M√≠nimo:** 8GB VRAM
- **Recomendado:** 12GB+ VRAM
- CPU funciona mas √© significativamente mais lento

## Modo Offline

O sistema suporta modo offline para todos os modelos:

```python
# Em src/config.py
OFFLINE_MODE = True
```

**Nota:** Execute `python scripts/download_models.py` primeiro para baixar todos os modelos necess√°rios.

## Limita√ß√µes e Considera√ß√µes

### Limita√ß√µes do SenseVoice:

1. **Idioma:** Melhor desempenho em ingl√™s e chin√™s
2. **Segmentos curtos:** Pode ter dificuldade em segmentos < 0.5s
3. **Ru√≠do de fundo:** Ambientes ruidosos afetam precis√£o

### Limita√ß√µes do Qwen3-TTS:

1. **Instru√ß√µes complexas:** Quanto mais espec√≠fica a instru√ß√£o, melhor o resultado
2. **Idiomas:** Melhor qualidade em chin√™s, ingl√™s e portugu√™s
3. **Consist√™ncia:** Pequenas varia√ß√µes nas instru√ß√µes podem gerar resultados diferentes

### Performance:

- An√°lise de emo√ß√µes adiciona ~30% ao tempo de processamento
- Processamento em batch otimiza o uso de GPU
- Cache de modelos acelera execu√ß√µes subsequentes

## Troubleshooting

### Problema: "SenseVoice n√£o encontrado"
**Solu√ß√£o:** Verificar se o modelo est√° instalado:
```bash
python -c "from transformers import AutoModel; AutoModel.from_pretrained('FunAudioLLM/SenseVoiceSmall')"
```

### Problema: "Emo√ß√µes sempre neutras"
**Solu√ß√£o:** 
- Verificar qualidade do √°udio (deve ter fala clara)
- Segmentos muito curtos podem n√£o ter emo√ß√£o detect√°vel
- √Åudio com muito ru√≠do afeta detec√ß√£o

### Problema: "TTS n√£o aplica emo√ß√µes"
**Solu√ß√£o:**
- Verificar se `ENABLE_EMOTION_ANALYSIS = True` em config.py
- Confirmar que motor_tts="qwen3" (MMS n√£o suporta instru√ß√µes emocionais)
- Verificar logs para confirmar que instru√ß√µes est√£o sendo geradas

## Refer√™ncias

- **SenseVoice:** https://huggingface.co/FunAudioLLM/SenseVoiceSmall
- **Qwen3-TTS:** https://github.com/maxwellamaral/Qwen3-TTS
- **Whisper:** https://github.com/openai/whisper
- **Documenta√ß√£o Transformers:** https://huggingface.co/docs/transformers

## Contribuindo

Para adicionar novas emo√ß√µes ou melhorar as instru√ß√µes:

1. Editar `EMOTION_INSTRUCTIONS` em `src/services/emotion.py`
2. Testar com v√°rios segmentos de √°udio
3. Ajustar instru√ß√µes baseado nos resultados do Qwen3-TTS

---

**√öltima Atualiza√ß√£o:** 28/01/2026
