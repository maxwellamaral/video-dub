
import os
import shutil
import time
from src.config import *
from src.services.audio import extrair_referencia_voz, extrair_audio, transcrever_audio_whisper, transcrever_com_emocao
from src.services.translation import traduzir_segmentos
from src.services.tts import TTSEngine
from src.services.video import VideoEditor
from src.utils import segmentos_para_srt, segmentos_para_srt_com_emocao, extrair_estatisticas_emocoes

def executar_pipeline(caminho_video, idioma_origem, idioma_destino, idioma_voz, 
                     motor_tts, modo_encoding, progress_callback=None,
                     qwen3_mode="custom", qwen3_speaker="vivian", qwen3_instruct=""):
    """
    Pipeline principal de dublagem de v√≠deo.

    Args:
        caminho_video (str): Caminho do v√≠deo de entrada.
        idioma_origem (str): C√≥digo do idioma original (ex: 'eng_Latn').
        idioma_destino (str): C√≥digo do idioma de destino (ex: 'por_Latn').
        idioma_voz (str): C√≥digo do idioma da voz gerada (ex: 'por').
        motor_tts (str): Motor de TTS a usar ('mms', 'coqui', 'qwen3').
        modo_encoding (str): Modo de codifica√ß√£o ('rapido' ou 'qualidade').
        progress_callback (callable, optional): Fun√ß√£o para notificar progresso.
        qwen3_mode (str): Modalidade Qwen3 ('custom', 'design', 'clone').
        qwen3_speaker (str): Speaker para CustomVoice (ex: 'Vivian').
        qwen3_instruct (str): Instru√ß√£o de voz para CustomVoice/VoiceDesign.

    Returns:
        bool: True se o pipeline foi executado com sucesso, False caso contr√°rio.
    """
    def log(msg):
        print(msg)
        if progress_callback:
            try:
                progress_callback(msg)
            except: pass

    log("="*60)
    log(f"PIPELINE WEB: {motor_tts.upper()} | {modo_encoding.upper()}")
    log("="*60)
    
    # 0. Limpeza pr√©via
    nome_saida = f"{VIDEO_SAIDA_BASE}_{motor_tts}.mp4"
    if os.path.exists(nome_saida):
        try: os.remove(nome_saida)
        except: pass
    
    # Limpeza de arquivos de legenda e √°udio antigos
    for arquivo in [AUDIO_REFERENCIA, AUDIO_EXTRAIDO, LEGENDA_ORIGINAL, LEGENDA_TRADUZIDA, LEGENDA_FINAL]:
        if os.path.exists(arquivo):
            try: os.remove(arquivo)
            except: pass

    # 1. Extra√ß√£o de √Åudio
    log("1. Extraindo √°udio original...")
    if not extrair_audio(caminho_video, AUDIO_EXTRAIDO, log_callback=log): 
        log("‚ùå Falha na extra√ß√£o de √°udio.")
        return False
    
    # Extra√ß√£o de refer√™ncia de voz para Voice Clone (Qwen3)
    if motor_tts == "qwen3" and qwen3_mode == "clone":
        log("1.1. Extraindo refer√™ncia de voz (Voice Clone)...")
        extrair_referencia_voz(caminho_video, AUDIO_REFERENCIA, log_callback=log)
        
    # 2. Transcri√ß√£o
        log("2. Transcrevendo √°udio e analisando emo√ß√µes...")
    
        # Usar transcri√ß√£o com an√°lise de emo√ß√µes se habilitado
        if ENABLE_EMOTION_ANALYSIS:
            log("   Modo: Whisper + SenseVoice (Transcri√ß√£o + Emo√ß√µes)")
            segmentos = transcrever_com_emocao(
                AUDIO_EXTRAIDO,
                modelo_whisper="openai/whisper-base",
                modelo_sensevoice=SENSEVOICE_MODEL,
                log_callback=log
            )
        else:
            log("   Modo: Whisper apenas (Transcri√ß√£o simples)")
            segmentos = transcrever_audio_whisper(AUDIO_EXTRAIDO, log_callback=log)
    
    if not segmentos: 
        log("‚ùå Nenhum di√°logo detectado ou falha na transcri√ß√£o.")
        return False
    
        # Exibir estat√≠sticas de emo√ß√µes se dispon√≠veis
        if ENABLE_EMOTION_ANALYSIS and "emotion" in segmentos[0]:
            stats = extrair_estatisticas_emocoes(segmentos)
            log(f"   üìä Estat√≠sticas de Emo√ß√µes:")
            log(f"      Total de segmentos: {stats['total']}")
            log(f"      Emo√ß√£o predominante: {stats['predominante']}")
            for emocao, count in stats['emocoes'].items():
                percentual = stats['distribuicao_percentual'][emocao]
                log(f"      - {emocao}: {count} ({percentual:.1f}%)")
    
    # Salvar legenda original
        with open(LEGENDA_ORIGINAL, "w", encoding="utf-8") as f:
            if ENABLE_EMOTION_ANALYSIS and INCLUDE_EMOTION_TAGS_IN_SUBTITLES:
                f.write(segmentos_para_srt_com_emocao(segmentos, incluir_tag_emocao=True))
            else:
                f.write(segmentos_para_srt(segmentos))
    
    # 3. Tradu√ß√£o
    log(f"3. Traduzindo para {idioma_destino} (NLLB)...")
    seg_traduzidos = traduzir_segmentos(segmentos, idioma_origem, idioma_destino, log_callback=log)
    
        # Preservar emo√ß√µes ap√≥s tradu√ß√£o
        if ENABLE_EMOTION_ANALYSIS and "emotion" in segmentos[0]:
            for i, seg_trad in enumerate(seg_traduzidos):
                if i < len(segmentos):
                    seg_trad["emotion"] = segmentos[i].get("emotion", "neutral")
                    seg_trad["emotion_pt"] = segmentos[i].get("emotion_pt", "neutro")
                    seg_trad["emotion_instruction"] = segmentos[i].get("emotion_instruction", "")
    
    # Salvar legenda traduzida
        with open(LEGENDA_TRADUZIDA, "w", encoding="utf-8") as f:
            if ENABLE_EMOTION_ANALYSIS and INCLUDE_EMOTION_TAGS_IN_SUBTITLES:
                f.write(segmentos_para_srt_com_emocao(seg_traduzidos, incluir_tag_emocao=True))
            else:
                f.write(segmentos_para_srt(seg_traduzidos))
    
    # 4. S√≠ntese TTS
    log(f"4. Sintetizando Voz ({motor_tts})...")
    tts = TTSEngine(
        motor=motor_tts, 
        idioma=idioma_voz, 
        ref_wav=AUDIO_REFERENCIA,
        log_callback=log,
        qwen3_mode=qwen3_mode,
        qwen3_speaker=qwen3_speaker,
        qwen3_instruct=qwen3_instruct
    )
    
        # Preparar dados para s√≠ntese: incluir emo√ß√µes se dispon√≠veis
        if ENABLE_EMOTION_ANALYSIS and "emotion_instruction" in seg_traduzidos[0]:
            log("   üé≠ Aplicando emo√ß√µes detectadas ao TTS...")
            textos = [
                {
                    "text": s["text"],
                    "emotion_instruction": s.get("emotion_instruction", "")
                }
                for s in seg_traduzidos
            ]
        else:
            textos = [s["text"] for s in seg_traduzidos]
    
    # Retorna lista de (audio_np, sample_rate)
    log(f"   Gerando √°udio para {len(textos)} segmentos...")
    audios = tts.sintetizar_batch(textos)
    
    # 5. Edi√ß√£o de V√≠deo
    log("5. Editando e Sincronizando V√≠deo...")
    editor = VideoEditor(caminho_video)
    temp_files = []
    ok = False
    
    try:
        clips, temp_wavs, legendas_sync = editor.processar_segmentos(seg_traduzidos, audios, log_callback=log)
        temp_files.extend(temp_wavs)
        
        log(f"   Renderizando v√≠deo final: {os.path.basename(nome_saida)}")
        ok = editor.renderizar_video(clips, nome_saida, modo=modo_encoding, log_callback=log)
        if ok:
            # Salvar SRT final
            with open(LEGENDA_FINAL, "w", encoding="utf-8") as f:
                    if ENABLE_EMOTION_ANALYSIS and INCLUDE_EMOTION_TAGS_IN_SUBTITLES:
                        f.write(segmentos_para_srt_com_emocao(legendas_sync, incluir_tag_emocao=True))
                    else:
                        f.write(segmentos_para_srt(legendas_sync))
            log(f"‚úÖ Pipeline conclu√≠da com sucesso!")
            
    except Exception as e:
        log(f"‚ùå Falha na edi√ß√£o: {e}")
        ok = False
        import traceback
        traceback.print_exc()
        
    finally:
        editor.close()
        # Limpeza robusta
        log("   üßπ Limpando arquivos tempor√°rios...")
        for f in temp_files:
            try:
                if os.path.exists(f): os.remove(f)
            except: 
                time.sleep(0.5)
                try: os.remove(f)
                except: pass
                
    return ok
