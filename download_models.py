"""
Script para baixar todos os modelos necess√°rios para execu√ß√£o offline.

Execute este script uma vez com conex√£o √† internet para baixar todos os modelos.
Depois, o projeto funcionar√° sem conex√£o.
"""

import os
from transformers import pipeline, VitsModel, AutoTokenizer
from TTS.api import TTS
import torch

def download_models():
    print("="*60)
    print("BAIXANDO MODELOS PARA EXECU√á√ÉO OFFLINE")
    print("="*60)
    
    # 1. Whisper (Transcri√ß√£o de √Åudio)
    print("\n1Ô∏è‚É£ Baixando Whisper (ASR)...")
    try:
        pipe_asr = pipeline(
            "automatic-speech-recognition",
            model="openai/whisper-base",
            device=-1  # CPU para download
        )
        print("   ‚úì Whisper baixado com sucesso!")
    except Exception as e:
        print(f"   ‚úó Erro ao baixar Whisper: {e}")
    
    # 2. NLLB (Tradu√ß√£o)
    print("\n2Ô∏è‚É£ Baixando NLLB-200 (Tradu√ß√£o)...")
    try:
        pipe_translation = pipeline(
            "translation",
            model="facebook/nllb-200-distilled-600M",
            device=-1
        )
        print("   ‚úì NLLB-200 baixado com sucesso!")
    except Exception as e:
        print(f"   ‚úó Erro ao baixar NLLB: {e}")
    
    # 3. MMS-TTS (S√≠ntese de Voz)
    print("\n3Ô∏è‚É£ Baixando MMS-TTS (Portugu√™s)...")
    try:
        modelo_nome = "facebook/mms-tts-por"
        tokenizer = AutoTokenizer.from_pretrained(modelo_nome)
        model = VitsModel.from_pretrained(modelo_nome)
        print("   ‚úì MMS-TTS (por) baixado com sucesso!")
    except Exception as e:
        print(f"   ‚úó Erro ao baixar MMS-TTS: {e}")
    
    # 4. Coqui XTTS v2 (Opcional - clonagem de voz)
    print("\n4Ô∏è‚É£ Baixando Coqui XTTS v2 (Clonagem de Voz)...")
    try:
        os.environ["COQUI_TOS_AGREED"] = "1"
        
        # Patch para PyTorch 2.6+
        original_load = torch.load
        def patched_load(*args, **kwargs):
            kwargs['weights_only'] = False
            return original_load(*args, **kwargs)
        torch.load = patched_load
        
        tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2")
        torch.load = original_load
        
        print("   ‚úì Coqui XTTS v2 baixado com sucesso!")
    except Exception as e:
        print(f"   ‚úó Erro ao baixar Coqui: {e}")
    
    # Informa√ß√µes sobre cache
    print("\n" + "="*60)
    print("‚úÖ DOWNLOAD CONCLU√çDO!")
    print("="*60)
    print("\nOs modelos foram salvos no cache local:")
    
    if os.name == 'nt':  # Windows
        cache_path = os.path.expanduser("~/.cache/huggingface/hub")
        print(f"   üìÅ {cache_path}")
    else:
        print("   üìÅ ~/.cache/huggingface/hub")
    
    print("\nüí° Agora voc√™ pode executar o projeto sem conex√£o √† internet!")
    print("   Use: uv run python main_refactored.py")

if __name__ == "__main__":
    download_models()
